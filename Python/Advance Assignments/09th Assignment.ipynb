{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In Python 3.X, what are the names and functions of string object types?\n",
    "\n",
    "   The following are the names and functions of string object types in Python 3.X\n",
    "   1. isdecimal(): Checks if all characters in the string are decimal.\n",
    "   2. isalnum(): Checks if all characters in the string are alphanumeric.\n",
    "   3. istitle(): Checks if the string is in title case (first character of each word capitalized).\n",
    "   4. partition(sub_string): Splits the string at the first occurrence of the specified substring and returns a tuple of three elements.\n",
    "   5. rpartition(sub_string): Splits the string at the last occurrence of the specified substring and returns a tuple of three elements.\n",
    "   6. isidentifier(): Checks if the string is a valid identifier name.\n",
    "   7. len(string): Returns the length of the string.\n",
    "   8. index(sub_string): Returns the lowest index of the substring if found in the string.\n",
    "   9. rindex(sub_string): Returns the highest index of the substring if found in the string.\n",
    "   10. max(string): Returns the highest alphabetical character in the string based on ASCII values.\n",
    "   11. min(string): Returns the lowest alphabetical character in the string based on ASCII values.\n",
    "   12. splitlines(): Returns a list of lines in the string.\n",
    "   13. capitalize(): Returns the string with the first character capitalized.\n",
    "   14. upper(): Returns the string with all characters in uppercase.\n",
    "   15. lower(): Returns the string with all characters in lowercase.\n",
    "   16. casefold(): Returns the string in lowercase suitable for caseless comparisons.\n",
    "   17. expandtabs(no_of_spaces): Replaces tabs in the string with the specified number of spaces.\n",
    "   18. find(sub_string): Returns the lowest index of the substring if found in the string, else returns -1.\n",
    "   19. rfind(sub_string): Returns the highest index of the substring if found in the string, else returns -1.\n",
    "   20. count(char): Returns the number of occurrences of the character in the string.\n",
    "   21. split(sep): Returns a list of words separated by the specified separator, default is whitespace.\n",
    "   22. rsplit(sep): Returns a list of words separated by the specified separator scanning from the end.\n",
    "   23. lstrip(): Returns a copy of the string with leading whitespaces removed.\n",
    "   24. rstrip(): Returns a copy of the string with trailing whitespaces removed.\n",
    "   25. strip(): Returns a copy of the string with both leading and trailing whitespaces removed.\n",
    "   26. swapcase(): Swaps lowercase characters with uppercase and vice versa.\n",
    "   27. join(list): Concatenates a list of words with intervening occurrences of the string.\n",
    "   28. translate(mapping_table): Translates the characters using the specified mapping table.\n",
    "   29. maketrans(dict): Creates a mapping translation table usable for string translation.\n",
    "   30. replace(char_1, char_2): Replaces all occurrences of char_1 with char_2 in the string.\n",
    "   31. encode(): Encodes the string into any encoding supported by Python, default encoding is UTF-8.\n",
    "   32. ljust(no_of_spaces): Left-justifies the string in a field of the given width.\n",
    "   33. rjust(no_of_spaces): Right-justifies the string in a field of the given width.\n",
    "   34. center(no_of_spaces): Center-justifies the string in a field of the given width.\n",
    "   35. zfill(length): Fills the string with zeros until it reaches the specified length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n",
      "('\"I could eat ', 'bananas', ' all day, bananas are my favorite fruit\"')\n",
      "('\"I could eat bananas all day, ', 'bananas', ' are my favorite fruit\"')\n",
      "True\n",
      "17\n",
      "6\n",
      "6\n",
      "t\n",
      "A\n",
      "['iNeuron ', ' Full Stack ', ' Data Science ', ' Course ']\n",
      "Finding nemo\n",
      "DATA PIPELINES\n",
      "ml ops\n",
      "doloris jane umbridge\n",
      "Data science    Data Analyst\n",
      "6\n",
      "6\n",
      "2\n",
      "['iNeuro', '']\n",
      "['iNeuro', '']\n",
      "EDA \n",
      " EDA\n",
      "EDA\n",
      "eXPLORATORY dATA aNALYSIS\n",
      "Iris_flower_Dataset\n",
      "Hello Pam!\n",
      "Hello Pam!\n",
      "iNeuro2\n",
      "b'Natural Language Processing'\n",
      "Nemo      \n",
      "      Nemo\n",
      "   Nemo   \n",
      "00000Hello\n"
     ]
    }
   ],
   "source": [
    "print('1234567890'.isdecimal())\n",
    "print('iNeuronFullStackDS'.isalnum())\n",
    "print('iNeuron Full Stack Data science'.istitle())\n",
    "print('\"I could eat bananas all day, bananas are my favorite fruit\"'.partition('bananas'))\n",
    "print('\"I could eat bananas all day, bananas are my favorite fruit\"'.rpartition('bananas'))\n",
    "print('GeeksForFreaks'.isidentifier())\n",
    "print(len('Linear Regression'))\n",
    "print('iNeuron'.index('n'))\n",
    "print('iNeuron'.rindex('n'))\n",
    "print(max('Data_Scientist'))\n",
    "print(min('Data_Analyst'))\n",
    "print('iNeuron \\n Full Stack \\n Data Science \\n Course '.splitlines())\n",
    "print('finding nemo'.capitalize())\n",
    "print('data pipelines'.upper())\n",
    "print('ML OPS'.lower())\n",
    "print('Doloris Jane Umbridge'.casefold())\n",
    "print('Data science\\tData Analyst'.expandtabs(8))\n",
    "print('iNeuron'.find('n'))\n",
    "print('iNeuron'.rfind('n'))\n",
    "print('Transformers'.count('s'))\n",
    "print('iNeuron'.split('n'))\n",
    "print('iNeuron'.rsplit('n'))\n",
    "print(' EDA '.lstrip())\n",
    "print(' EDA '.rstrip())\n",
    "print(' EDA '.strip())\n",
    "print('Exploratory Data Analysis'.swapcase())\n",
    "print('_'.join(['Iris','flower','Dataset']))\n",
    "\n",
    "mydict = {83:  80}\n",
    "print(\"Hello Sam!\".translate(mydict))\n",
    "\n",
    "txt = \"Hello Sam!\"\n",
    "mytable = txt.maketrans(\"S\", \"P\")\n",
    "print(txt.translate(mytable))\n",
    "\n",
    "print('iNeuron'.replace('n','2'))\n",
    "print('Natural Language Processing'.encode())\n",
    "print('Nemo'.ljust(10))\n",
    "print('Nemo'.rjust(10))\n",
    "print('Nemo'.center(10))\n",
    "print('Hello'.zfill(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. How do the string forms in Python 3.X vary in terms of operations?\n",
    "\n",
    "    In Python 3.X, strings are by default represented as Unicode, while in Python 2, Unicode strings need to be explicitly indicated by using the 'u' prefix.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. In Python 3.X, how do you put non-ASCII Unicode characters in a string?\n",
    "\n",
    "    In Python 3.x, you can include non-ASCII Unicode characters directly in a string by using Unicode escape sequences or by directly inserting the characters into the string literal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a non-ASCII character: ©\n",
      "This is a non-ASCII character: ©\n"
     ]
    }
   ],
   "source": [
    "# Using Unicode escape sequence\n",
    "unicode_str = \"This is a non-ASCII character: \\u00A9\"\n",
    "print(unicode_str)\n",
    "\n",
    "# Directly inserting Unicode characters\n",
    "unicode_str = \"This is a non-ASCII character: ©\"\n",
    "print(unicode_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. In Python 3.X, what are the key differences between text-mode and binary-mode files?\n",
    "\n",
    "    In Python 3.X, the key differences between text-mode and binary-mode files are as follows:\n",
    "\n",
    "    - Text-mode files:\n",
    "        - Contain textual information composed of alphabets, digits, and special characters or symbols.\n",
    "        - Automatically decode the data when reading, based on the platform default or the specified encoding.\n",
    "        - Reading operation returns data as a str object, while writing operation takes a str and automatically encodes it before writing to the file.\n",
    "        - Support universal end-of-line translation and encoding specification arguments.\n",
    "\n",
    "    - Binary-mode files:\n",
    "        - Contain raw binary data or a compiled version of a text file.\n",
    "        - Reading data does not decode it and returns content as a bytes object.\n",
    "        - Writing operation takes a bytes object and transfers it to the file unchanged\n",
    "        - Accept bytes or bytearray objects for writing data to the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. How can you interpret a Unicode text file containing text encoded in a different encoding than your platform's default?\n",
    "\n",
    "    To interpret a Unicode text file encoded in a different encoding than your platform's default, we can use the `encode()` and `decode()` methods in Python. By default, the encoding parameter is UTF-8.\n",
    "\n",
    "    The `encode()` method converts Unicode strings to encoded byte strings, while the `decode()` method decodes byte strings to Unicode strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. What is the best way to make a Unicode text file in a particular encoding format?\n",
    "\n",
    "    The recommended approach to create a Unicode text file in a specific encoding format is as follows:\n",
    "\n",
    "    - Encode the string using str.encode(encoding), specifying the desired encoding format (e.g., UTF-8).\n",
    "\n",
    "    - Open the file using open(file, mode) with mode set to 'wb' to write in binary mode, preserving the UTF-8 format.\n",
    "\n",
    "    - Use file.write(data) to write the encoded data to the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, world! \\xf0\\x9f\\x8c\\x8d'\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello, world! 🌍\"\n",
    "\n",
    "encoded_text = text.encode('utf-8')\n",
    "\n",
    "with open('unicode_file.txt', 'wb') as file:\n",
    "    file.write(encoded_text)\n",
    "\n",
    "with open(\"unicode_file.txt\", \"rb\") as r_file:\n",
    "    data = r_file.read()\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. What qualifies ASCII text as a form of Unicode text?\n",
    "\n",
    "    ASCII text qualifies as a form of Unicode text because Unicode encompasses most written languages globally, including ASCII. While ASCII primarily represents lowercase and uppercase letters, digits, and basic symbols, Unicode expands upon this by incorporating a broader range of characters. Unicode includes characters from various languages, mathematical symbols, historical scripts, and even emojis, making it more comprehensive than ASCII. Therefore, ASCII text is a subset of Unicode text, with Unicode providing greater versatility and character coverage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. How much of an effect does the change in string types in Python 3.X have on your code?\n",
    "\n",
    "    The transition from Python 2 to Python 3 significantly impacts code due to changes in string types. Unlike Python 2, where strings are represented as ASCII by default and need the 'u' prefix for Unicode encoding, Python 3 stores strings as Unicode by default. This default Unicode encoding in Python 3 offers greater versatility, enabling the storage of characters from various languages, emojis, and symbols. As a result, Python 3's Unicode strings provide enhanced support for internationalization and localization efforts compared to the ASCII strings used in Python 2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
